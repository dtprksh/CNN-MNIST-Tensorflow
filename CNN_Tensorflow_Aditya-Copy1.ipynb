{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Tensorflow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for initializing weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(shape):\n",
    "    w=tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for initializing biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_biases(shape):\n",
    "    b=tf.Variable(tf.constant(0.1,shape=shape))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X,w):\n",
    "    return tf.nn.conv2d(X,w,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(X):\n",
    "    return tf.nn.max_pool(X,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Convolution Layer (adding biases after convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_layer(X,shape):\n",
    "    w=init_weight(shape)\n",
    "    b=init_biases([shape[3]])\n",
    "    return tf.nn.relu(conv2d(X,w)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(X,size):\n",
    "    feature=int(X.get_shape()[1])\n",
    "    w=init_weight([feature,size])\n",
    "    b=init_biases([size])\n",
    "    return tf.matmul(X,w)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Placeholder for input and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,shape=[None,784])\n",
    "y_true=tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Input for Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image=tf.reshape(X,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying two layers of Subsequent Convolution and Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1=convolution_layer(X_image,shape=[5,5,1,16])\n",
    "max_pool1=max_pool(conv1)\n",
    "conv2=convolution_layer(max_pool1,shape=[5,5,16,32])\n",
    "max_pool2=max_pool(conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 4D Tensor to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool2_flat=tf.reshape(max_pool2,[-1,49*32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Fully Connected Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn=tf.nn.relu(fully_connected_layer(max_pool2_flat,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=fully_connected_layer(fcn,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Softmax Regression and calculating loss with cross entropy and train the model with Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our model: Batch_Size=50, We train over 500 batches. Last Batch has an accuracy of 98% and we have an accuracy of 98.6% over first 500 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14\n",
      "0.28\n",
      "0.32\n",
      "0.36\n",
      "0.44\n",
      "0.3\n",
      "0.44\n",
      "0.36\n",
      "0.66\n",
      "0.56\n",
      "0.58\n",
      "0.64\n",
      "0.48\n",
      "0.58\n",
      "0.58\n",
      "0.66\n",
      "0.84\n",
      "0.76\n",
      "0.86\n",
      "0.84\n",
      "0.92\n",
      "0.86\n",
      "0.86\n",
      "0.72\n",
      "0.94\n",
      "0.88\n",
      "0.8\n",
      "0.84\n",
      "0.78\n",
      "0.78\n",
      "0.88\n",
      "0.82\n",
      "0.86\n",
      "0.9\n",
      "0.78\n",
      "0.94\n",
      "0.88\n",
      "0.88\n",
      "0.82\n",
      "0.94\n",
      "0.9\n",
      "0.84\n",
      "0.9\n",
      "0.92\n",
      "0.86\n",
      "0.88\n",
      "0.9\n",
      "0.94\n",
      "0.78\n",
      "0.98\n",
      "0.9\n",
      "0.9\n",
      "0.88\n",
      "0.92\n",
      "0.94\n",
      "0.86\n",
      "0.94\n",
      "0.9\n",
      "0.88\n",
      "0.96\n",
      "0.94\n",
      "0.96\n",
      "0.98\n",
      "0.9\n",
      "0.9\n",
      "0.88\n",
      "0.92\n",
      "0.88\n",
      "0.88\n",
      "0.9\n",
      "0.94\n",
      "0.9\n",
      "0.86\n",
      "0.92\n",
      "0.96\n",
      "0.92\n",
      "0.92\n",
      "0.82\n",
      "0.9\n",
      "0.82\n",
      "0.92\n",
      "0.9\n",
      "0.9\n",
      "0.86\n",
      "0.96\n",
      "0.94\n",
      "0.92\n",
      "0.94\n",
      "0.96\n",
      "0.92\n",
      "0.88\n",
      "0.98\n",
      "0.92\n",
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "0.92\n",
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "0.88\n",
      "0.9\n",
      "0.92\n",
      "0.98\n",
      "0.9\n",
      "0.96\n",
      "0.94\n",
      "1.0\n",
      "0.96\n",
      "0.86\n",
      "0.94\n",
      "0.9\n",
      "0.92\n",
      "0.92\n",
      "0.9\n",
      "0.92\n",
      "0.98\n",
      "0.9\n",
      "0.96\n",
      "0.92\n",
      "0.92\n",
      "0.96\n",
      "0.9\n",
      "0.92\n",
      "0.96\n",
      "0.94\n",
      "0.94\n",
      "0.98\n",
      "0.94\n",
      "0.96\n",
      "0.92\n",
      "0.98\n",
      "0.92\n",
      "0.98\n",
      "0.9\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "0.94\n",
      "1.0\n",
      "0.96\n",
      "0.96\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "0.9\n",
      "0.96\n",
      "0.94\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "0.94\n",
      "0.96\n",
      "0.88\n",
      "0.98\n",
      "0.9\n",
      "0.98\n",
      "0.96\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "0.94\n",
      "0.92\n",
      "0.98\n",
      "1.0\n",
      "0.96\n",
      "1.0\n",
      "0.94\n",
      "0.92\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "0.92\n",
      "0.98\n",
      "0.94\n",
      "0.98\n",
      "0.92\n",
      "1.0\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "0.88\n",
      "0.98\n",
      "0.98\n",
      "0.86\n",
      "0.96\n",
      "0.98\n",
      "0.94\n",
      "0.94\n",
      "0.9\n",
      "0.96\n",
      "0.92\n",
      "1.0\n",
      "0.94\n",
      "0.9\n",
      "0.96\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.92\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "0.92\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.92\n",
      "0.96\n",
      "0.96\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "1.0\n",
      "0.96\n",
      "1.0\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "1.0\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "0.96\n",
      "0.94\n",
      "0.88\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "0.94\n",
      "1.0\n",
      "0.92\n",
      "0.98\n",
      "0.94\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "0.9\n",
      "0.96\n",
      "1.0\n",
      "0.94\n",
      "0.98\n",
      "0.94\n",
      "0.94\n",
      "0.98\n",
      "0.94\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "0.96\n",
      "0.92\n",
      "0.94\n",
      "0.94\n",
      "0.92\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.94\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "0.96\n",
      "0.94\n",
      "0.94\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "0.94\n",
      "0.96\n",
      "0.94\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.96\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "0.88\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "0.96\n",
      "0.96\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.96\n",
      "0.96\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "0.94\n",
      "0.98\n",
      "0.92\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "1.0\n",
      "0.94\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "0.94\n",
      "0.94\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "0.96\n",
      "1.0\n",
      "0.94\n",
      "0.98\n",
      "0.96\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "0.96\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "0.98\n",
      "0.94\n",
      "1.0\n",
      "0.98\n",
      "0.98\n",
      "1.0\n",
      "0.96\n",
      "1.0\n",
      "0.96\n",
      "0.98\n",
      "0.986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    steps=500\n",
    "    writer=tf.summary.FileWriter('./output',sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(steps):\n",
    "        batch_x,batch_y=mnist.train.next_batch(50)\n",
    "        sess.run(train_op,feed_dict={X:batch_x,y_true:batch_y})\n",
    "        prediction=tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "        accuracy=tf.reduce_mean(tf.cast(prediction,tf.float32))\n",
    "        print(sess.run(accuracy,feed_dict={X:batch_x,y_true:batch_y}))\n",
    "    print(sess.run(accuracy,feed_dict={X:mnist.test.images[:500,:],y_true:mnist.test.labels[:500,:]}))\n",
    "    saver.save(sess,'cnn/checkpoint.ckpt')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
